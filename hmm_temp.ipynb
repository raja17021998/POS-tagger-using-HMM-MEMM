{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm \n",
    "import csv\n",
    "import ast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       untagged_sentence tagged_sentence\n",
      "count              47340           47340\n",
      "unique             46610           46637\n",
      "top                ['.']    [(')', ')')]\n",
      "freq                  52              46\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   untagged_sentence  \\\n",
      "0  ['The', 'jury', 'further', 'said', 'in', 'term...   \n",
      "1  ['The', 'September-October', 'term', 'jury', '...   \n",
      "2  ['``', 'Only', 'a', 'relative', 'handful', 'of...   \n",
      "3  ['The', 'jury', 'said', 'it', 'did', 'find', '...   \n",
      "4  ['It', 'recommended', 'that', 'Fulton', 'legis...   \n",
      "5  ['The', 'grand', 'jury', 'commented', 'on', 'a...   \n",
      "6                             ['Merger', 'proposed']   \n",
      "7  ['However', ',', 'the', 'jury', 'said', 'it', ...   \n",
      "8  ['The', 'City', 'Purchasing', 'Department', ',...   \n",
      "9  ['It', 'urged', 'that', 'the', 'city', '``', '...   \n",
      "\n",
      "                                     tagged_sentence  \n",
      "0  [('The', 'AT'), ('jury', 'NN'), ('further', 'R...  \n",
      "1  [('The', 'AT'), ('September-October', 'NP'), (...  \n",
      "2  [('``', '``'), ('Only', 'RB'), ('a', 'AT'), ('...  \n",
      "3  [('The', 'AT'), ('jury', 'NN'), ('said', 'VB')...  \n",
      "4  [('It', 'PP'), ('recommended', 'VB'), ('that',...  \n",
      "5  [('The', 'AT'), ('grand', 'JJ'), ('jury', 'NN'...  \n",
      "6             [('Merger', 'NN'), ('proposed', 'VB')]  \n",
      "7  [('However', 'WR'), (',', ','), ('the', 'AT'),...  \n",
      "8  [('The', 'AT'), ('City', 'NN'), ('Purchasing',...  \n",
      "9  [('It', 'PP'), ('urged', 'VB'), ('that', 'CS')...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47340it [00:09, 4902.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    data.append(ast.literal_eval(row['tagged_sentence'])) # changing data-type of entries from 'str' to 'list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_train_tokens={}\n",
    "dict_train_tags={}\n",
    "len_of_data= len(data)\n",
    "for lists in data:\n",
    "    for tuples in lists:\n",
    "        token= tuples[0]\n",
    "        tag= tuples[1]\n",
    "    \n",
    "        if token in dict_train_tokens:\n",
    "            dict_train_tokens[token]+=1\n",
    "        else:\n",
    "            dict_train_tokens[token]=1\n",
    "            \n",
    "        if tag in dict_train_tags:\n",
    "            dict_train_tags[tag]+=1\n",
    "        else:\n",
    "            dict_train_tags[tag]=1\n",
    "        \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "len_train_tags=len(dict_train_tags)\n",
    "len_train_tokens=len(dict_train_tokens)\n",
    "print(len_train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_index_to_tags={}\n",
    "dict_tags_to_index={}\n",
    "\n",
    "idx=0\n",
    "\n",
    "for tag in dict_train_tags:\n",
    "    if idx not in dict_index_to_tags:\n",
    "        dict_index_to_tags[idx]= tag \n",
    "        dict_tags_to_index[tag]= idx \n",
    "    idx+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    " \n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_index_to_tokens={}\n",
    "dict_tokens_to_index={}\n",
    "idx=0\n",
    "\n",
    "for token in dict_train_tokens:\n",
    "    if idx not in dict_index_to_tokens:\n",
    "        dict_index_to_tokens[idx]= token\n",
    "        dict_tokens_to_index[token]=idx\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 51208)\n"
     ]
    }
   ],
   "source": [
    "#Emission Matrix\n",
    "emission_prob_matrix= np.zeros(( len_train_tags,len_train_tokens))\n",
    "for lists in data:\n",
    "    for tuples in lists:\n",
    "        token= tuples[0]\n",
    "        tag= tuples[1]\n",
    "        \n",
    "        emission_prob_matrix[dict_tags_to_index[tag]][dict_tokens_to_index[token]]+=1\n",
    "        \n",
    "        \n",
    "print(emission_prob_matrix.shape)\n",
    "\n",
    "\n",
    "row_sums = emission_prob_matrix.sum(axis=1)\n",
    "\n",
    "for i, row_sum in enumerate(row_sums):\n",
    "    if row_sum > 0:\n",
    "        emission_prob_matrix[i,:] /= row_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50)\n",
      "[[1.22478474e-05 6.08901736e-01 4.02954181e-03 ... 0.00000000e+00\n",
      "  1.22478474e-05 1.22478474e-04]\n",
      " [6.72132634e-03 1.03481754e-01 1.92144583e-02 ... 0.00000000e+00\n",
      "  5.86782458e-05 2.22443896e-03]\n",
      " [5.54844490e-02 1.57749904e-02 2.81901958e-02 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.83975426e-04]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.11111111e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  8.23129252e-01 6.80272109e-03]\n",
      " [1.47079447e-01 5.88360283e-02 6.72715297e-02 ... 0.00000000e+00\n",
      "  6.37443427e-05 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Transition Matrix\n",
    "transition_prob_matrix= np.zeros((len_train_tags+1, len_train_tags+1))\n",
    "\n",
    "for list in data:\n",
    "    len_list= len(list)\n",
    "    for tuple_index in range(len_list-1):\n",
    "        first_tuple_tag= list[tuple_index][1] \n",
    "        second_tuple_tag= list[tuple_index+1][1]\n",
    "        if tuple_index==0:\n",
    "            transition_prob_matrix[len_train_tags][dict_tags_to_index[first_tuple_tag]]+=1\n",
    "            \n",
    "        elif tuple_index==len_list-1-1:\n",
    "            transition_prob_matrix[dict_tags_to_index[second_tuple_tag]][len_train_tags]+=1\n",
    "        \n",
    "        \n",
    "        transition_prob_matrix[dict_tags_to_index[first_tuple_tag]][dict_tags_to_index[second_tuple_tag]]+=1\n",
    "            \n",
    "            \n",
    "print(transition_prob_matrix.shape)  \n",
    "row_sums = transition_prob_matrix.sum(axis=1)\n",
    "for i, row_sum in enumerate(row_sums):\n",
    "    if row_sum > 0:\n",
    "        transition_prob_matrix[i, :] /= row_sum\n",
    "print(transition_prob_matrix)\n",
    "            \n",
    "\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 51208)\n",
      "(50, 50)\n"
     ]
    }
   ],
   "source": [
    "print(emission_prob_matrix.shape)\n",
    "print(transition_prob_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"test_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_dict = pd.Series(df.untagged_sentence.values,index=df.id).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def viterbi_algorithm_new(sentence, transition_prob_matrix,emission_prob_matrix):\n",
    "    prob_matrix= np.zeros((len_train_tags, len_train_tokens))\n",
    "    m,n= prob_matrix.shape\n",
    "    len_of_sentence=len(sentence)\n",
    "    bp= np.zeros((m,n))\n",
    "    tags=[]\n",
    "    for i in range(len(sentence)):\n",
    "        for j in range(m):\n",
    "            \n",
    "            if sentence[i] not in dict_train_tokens:\n",
    "                emission_prob=1\n",
    "            else:\n",
    "                emission_prob=emission_prob_matrix[j][dict_tokens_to_index[sentence[i]]]\n",
    "            if(i==0):\n",
    "                prob_matrix[j][i]=transition_prob_matrix[len_train_tags][j]*emission_prob\n",
    "            else:\n",
    "                prev_col= prob_matrix[:,i-1].reshape(1,-1).copy()\n",
    "                for k in range(m):\n",
    "                    prev_col[0][k]*=(transition_prob_matrix[k][j]*emission_prob)\n",
    "                maxpos=np.argmax(prev_col)\n",
    "                prob_matrix[j][i]=prev_col[0][maxpos]\n",
    "                bp[j][i]=maxpos\n",
    "    last_tag_index=np.argmax(prob_matrix[:,-1])\n",
    "    tags.append(last_tag_index)\n",
    "\n",
    "    for i in range(len_of_sentence-1,0,-1):\n",
    "        tags.insert(0,int(bp[tags[0],i]))\n",
    "    tagged_sentence=[]\n",
    "    for i in range(len_of_sentence):\n",
    "        tagged_sentence.append((sentence[i],dict_index_to_tags[tags[i]]))\n",
    "    return tagged_sentence\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(test_data_dict):\n",
    "    data_list=[]\n",
    "    predictions={}\n",
    "    ctr=0\n",
    "    for id in test_data_dict:\n",
    "        data_list.append((id,test_data_dict[id]))\n",
    "        ctr+=1\n",
    "    for data_row in data_list:\n",
    "        # print(data_row[0])\n",
    "        temp=ast.literal_eval(data_row[1])\n",
    "        tagged_sentence=viterbi_algorithm_new(temp,transition_prob_matrix,emission_prob_matrix)\n",
    "        \n",
    "        predictions[data_row[0]]= tagged_sentence\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions=get_predictions(test_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(test_predictions,columns=['id', 'tagged_sentence'])\n",
    "output_csv_path = 'predictions_hmm.csv'\n",
    "predictions_df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predictions_hmm.csv'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "csv_file_path = 'predictions_hmm.csv'\n",
    "\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    writer.writerow(['id', 'tagged_sentence'])\n",
    "\n",
    "    for key, values in test_predictions.items():\n",
    "        writer.writerow([key, values])\n",
    "\n",
    "\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
